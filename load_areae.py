
import pandas as pd
import openpyxl
from sqlalchemy import text
import urllib
from sqlalchemy import create_engine
from sqlalchemy.exc import SQLAlchemyError

import pyodbc
import pandas as pd
from datetime import datetime, timedelta, date
from sqlalchemy import create_engine
import urllib
import argparse
import schedule
import time
import pandas as pd
import os
import pandas as pd
import numpy as np
# import schedule
import pandas as pd
# import xlsxwriter
import time
import pandas as pd
import pymongo
from pymongo import MongoClient
from pymongo import MongoClient
from datetime import datetime, timedelta
from sqlalchemy.orm import sessionmaker
import logging
from sqlalchemy.exc import IntegrityError
import logging
import os
from typing import List, Dict

from sqlalchemy.engine import Engine





def read_config(filename='config.txt'):
    """
    Reads a key-value configuration from a text file.

    :param filename: Name of the configuration file. Default is 'config.txt'.
    :return: A dictionary containing configuration key-value pairs.
    """
    script_path = os.path.abspath(__file__)
    config_path = os.path.join(os.path.dirname(script_path), filename)
    config = {}

    # Verify that the file exists
    if not os.path.exists(config_path):
        print(f"Error: Configuration file '{filename}' not found at {config_path}.")
        return {}

    try:
        with open(config_path, 'r') as file:
            for line in file:
                line = line.strip()
                # Skip empty lines or comments
                if not line or line.startswith('#'):
                    continue
                try:
                    key, value = line.split('=', 1)  # Limit split to at most 2 items
                    config[key.strip()] = value.strip().strip("'\"")  # Remove quotes
                except ValueError:
                    print(f"Warning: Skipping malformed line: {line}")
    except Exception as e:
        print(f"Error reading configuration file: {e}")
        return {}

    return config


# Get configuration values
config = read_config()

# Access individual parameters
excel_prod = config.get('excel_prod', '')
excel_test = config.get('excel_test', '')
environment = config.get('environment', '')
days_ago = 7
# Connection string
# Connection string
conn_str = (
    'DRIVER={ODBC Driver 17 for SQL Server};'
    'SERVER=lulimdbserver.database.windows.net;'
    'DATABASE=lulimdb;'
    'UID=shmuelstav;'
    'PWD=5tgbgt5@;'
    'TrustServerCertificate=yes;'
    'Encrypt=yes;'
)

# URL encode the connection string
params = urllib.parse.quote_plus(conn_str)

# Create SQLAlchemy engine
engine = create_engine(f'mssql+pyodbc:///?odbc_connect={params}', echo=False)


# Print or use the values as needed
print("Excel Prod:", excel_prod)
print("Excel Test:", excel_test)
print("Environment:", environment)

farms = '\\fandy farms'
reports = '\\current active flocks\\'
sheet_name_tmuta = 'tmuta'
sheet_name_sivuk = 'shivuk'
sheet_name_skila = '×¡×™×›×•× ×©×§×™×œ×•×ª'
sheet_name_mivne = '×©×˜×— ××‘× ×™×'
sheet_name_tarovet = '×ª×¢×¨×•×‘×ª'
excel_file_name_finish = 'current flock '
excel_end = '.xlsx'''
excel_middle_name = '\\current flock\\'

farms_new_folk = {}


# Functions
def read_excel(path, sheet_name):
    try:
        # df = pd.read_excel(path, sheet_name=sheet_name)
        # return df
        workbook = openpyxl.load_workbook(path, read_only=True, data_only=True)

        # Check if the specified sheet exists
        if sheet_name not in workbook.sheetnames:
            print(f"Sheet '{sheet_name}' not found.")
            return None

        # Access the specified sheet even if it's hidden
        sheet = workbook[sheet_name]

        # Read the sheet data into a DataFrame
        data = []
        for row in sheet.iter_rows(values_only=True):
            data.append(row)

        df = pd.DataFrame(data, columns=data[0])

        # Close the workbook
        workbook.close()

        return df

    except Exception as e:
        # Handle any exceptions (e.g., file not found, sheet not found) and return an empty DataFrame
        print(f"An error occurred: {str(e)}")
        return pd.DataFrame()


def subfolder_names(path):
    folder_names = []

    # List all directories and files in the given path
    entries = os.listdir(path)

    for entry in entries:
        entry_path = os.path.join(path, entry)

        # Check if the entry is a directory (subfolder)
        if os.path.isdir(entry_path):
            folder_names.append(entry)

    return folder_names


def translate(farm):
    translations = {
        'gotliv 4': '×’×•×˜×œ×™×‘ 4',
        'gotliv 2': '×’×•×˜×œ×™×‘ 2',
        'megadim': '××’×“×™×',
        'megido': '××’×™×“×•',
        'ranen': '×¨× ×Ÿ',
        'shaal morad': '×©×¢×œ - ××•×¨×“',
        'kalanit': '×›×œ× ×™×ª',
        'ramat zvi haim': '×¨××ª ×¦×‘×™ ×—×™×™×',
        'ramat zvi moshe': '×¨××ª ×¦×‘×™ ××©×”',
        'ramot naftali': '×¨××•×ª × ×¤×ª×œ×™',
        'ranen': '×¨× ×Ÿ',
        'shaal moyal': '×©×¢×œ - ××•×™××œ',
        'musayel': '××•×¡×™×™×œ',
        'sigler': '×¡×™×’×œ×¨',
        'gazit': '×’×–×™×ª',
        'sadmot dvora': '×©×“××•×ª ×“×‘×•×¨×”',
        'mawiya': '××¢××•×•×™×”',
        'sharona': '×©×¨×•× ×”'
        # Add more translations as needed
    }

    # Check if farm exists in translations dictionary
    if farm in translations:
        return translations[farm]
    else:
        print(f"Translation not found for '{farm}'")
        return f"Translation not found for '{farm}'"



def clean_and_filter_data(df):
    if df is None or df.empty:
        return pd.DataFrame()

    # ×©×œ×‘ 1: ×”×¡×¨ ×©×•×¨×•×ª ×•×¢××•×“×•×ª ×¨×™×§×•×ª ×œ×’××¨×™
    df = df.dropna(how='all').dropna(axis=1, how='all')

    # ×©×œ×‘ 2: ××¤×¡ ××™× ×“×§×¡
    df = df.reset_index(drop=True)

    # ×©×œ×‘ 3: ×§×— ×¨×§ ××ª ×©×ª×™ ×”×¢××•×“×•×ª ×”×¨××©×•× ×•×ª
    df = df.iloc[:, :2]

    # ×©×œ×‘ 3.5: ×”×¤×•×š ××ª ×”×©×•×¨×” ×”×¨××©×•× ×” ×œ×›×•×ª×¨×•×ª
    df.columns = df.iloc[0]
    df = df[1:]  # ××—×§ ××ª ×”×©×•×¨×” ×”×¨××©×•× ×” ×›×™ ×”×™× ×”×¤×›×” ×œ×›×•×ª×¨×ª

    # ×©×œ×‘ 4: ×¡× ×Ÿ ×¨×§ ×©×•×¨×•×ª ×©×‘×”×Ÿ ×”×¢×¨×š ×‘×¢××•×“×” ×”×¨××©×•× ×” ××ª×—×™×œ ×‘××¡×¤×¨
    first_col = df.columns[0]
    df = df[df[first_col].astype(str).str.match(r'^\d')]

    # ××¤×¡ ××ª ×”××™× ×“×§×¡ ×©×•×‘ ×œ××—×¨ ×”×¡×™× ×•×Ÿ
    df = df.reset_index(drop=True)

    return df

def prepare_rows_for_db(df, farm_name):
    if df is None or df.empty:
        return []

    # × × ×™×— ×©×™×© ×œ×š ×¤×•× ×§×¦×™×™×ª ×ª×¨×’×•×
    translated_farm = translate(farm_name)

    # ×”×•×¡×£ ×¢××•×“×ª ×©× ×—×•×•×”
    df['farm_name'] = translated_farm

    # ×”××¨×” ×œ×¨×©×™××ª ××™×œ×•× ×™× (dict) â€“ ××‘× ×” ×©××ª××™× ×œ-SQLAlchemy ××• ×”×›× ×¡×ª DB ××—×¨×ª
    rows = df.to_dict(orient='records')

    return rows


def transform_and_prepare_for_db(rows_list):
    import pandas as pd

    if not rows_list:
        return []

    # ×”××¨×” ×œ-DataFrame
    df = pd.DataFrame(rows_list)

    # ××¤×ª ×©××•×ª ×¢××•×“×•×ª
    rename_map = {
        "×©× ×—×•×•×”": "farm_name",
        "××¡' ××‘× ×”": "mivne",
        '×"×¨': "area"
    }

    # ×”×—×œ×¤×ª ×©××•×ª ×¢××•×“×•×ª (×¨×§ ×× ×§×™×™××™×)
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

    # ×”×—×–×¨×ª ×¨×©×™××” ×©×œ dicts
    return df.to_dict(orient='records')


def insert_if_not_exists(engine: Engine, rows_list: List[Dict[str, any]]) -> None:
    """
    ××‘×¦×¢ INSERT ×œ×ª×•×š dbo.farms_structures ×¨×§ ×× ×”×¨×©×•××” ×œ× ×§×™×™××ª ×›×‘×¨.

    :param engine: ××•×‘×™×™×§×˜ SQLAlchemy Engine
    :param rows_list: ×¨×©×™××” ×©×œ ××™×œ×•× ×™× ×‘×¤×•×¨××˜:
                      [{"farm_name": ..., "mivne": ..., "area": ...}, ...]
    """
    if not rows_list:
        print("ğŸ”¹ No data to insert. rows_list is empty.")
        return

    # ×‘×“×™×§×” ×©×›×œ ×”×©×“×•×ª ×”×“×¨×•×©×™× ×§×™×™××™× ×‘×›×œ ×©×•×¨×”
    required_keys = {"farm_name", "mivne", "area"}
    for i, row in enumerate(rows_list):
        if not required_keys.issubset(row.keys()):
            raise ValueError(f"âŒ Row {i} is missing required keys: {required_keys - row.keys()}")

    insert_sql = text("""
        INSERT INTO dbo.farms_structures (farm_name, mivne, area)
        SELECT :farm_name, :mivne, :area
        WHERE NOT EXISTS (
            SELECT 1 FROM dbo.farms_structures
            WHERE farm_name = :farm_name AND mivne = :mivne AND area = :area
        )
    """)

    try:
        with engine.begin() as conn:  # ×× ×”×œ ×˜×¨× ×–×§×¦×™×”
            conn.execute(insert_sql, rows_list)
            print(f"âœ… Inserted {len(rows_list)} rows if not already existing.")
    except Exception as e:
        print(f"âŒ Failed to insert rows: {e}")
        raise

def run_load_area():
    farms_names = subfolder_names(excel_prod + farms)
    tmuta_results = pd.DataFrame()
    for farm in farms_names:

        path = f"{excel_prod}{farms}\\{farm}{excel_middle_name}{excel_file_name_finish}{farm}{excel_end}"
        # path = 'C:\\Users\\User\\Dropbox\\BMC\\prod\\fandy farms\\shaal moyal\\current flock\\current flock shaal moyal.xlsx'
        data = read_excel(path, sheet_name_mivne)

        if not data.empty:
            df_end =  clean_and_filter_data(data)
            df_to_df = prepare_rows_for_db(df_end,farm)
            df_to_df = transform_and_prepare_for_db(df_to_df)
            insert_if_not_exists(engine, df_to_df)




def run_file():
    # ×”×’×“×¨×ª ××—×¨×•×–×ª ×”×—×™×‘×•×¨
    conn_str = (
        'DRIVER={ODBC Driver 17 for SQL Server};'
        'SERVER=lulimdbserver.database.windows.net;'
        'DATABASE=lulimdb;'
        'UID=shmuelstav;'
        'PWD=5tgbgt5@;'
        'TrustServerCertificate=yes;'
        'Encrypt=yes;'
    )
    params = urllib.parse.quote_plus(conn_str)
    engine = create_engine(f'mssql+pyodbc:///?odbc_connect={params}', fast_executemany=True)

    # ×§×¨×™××ª ×§×•×‘×¥ ×”××§×¡×œ
    df = pd.read_excel("C:/Users/User/Documents/farm_area.xlsx")
    df = df[['farm_name', 'mivne', 'area']].dropna()

    # × ×™×§×•×™ ×©×“×” farm_name â€” ×©×•××¨ ××•×ª×™×•×ª ×¢×‘×¨×™×•×ª, ×× ×’×œ×™×•×ª, ×¡×¤×¨×•×ª, ×¨×•×•×—×™× ×•××§×¤×™×
    df['farm_name'] = df['farm_name'].astype(str).str.strip().str.replace(r'[^×-×ªa-zA-Z0-9\s-]', '', regex=True)

    # ×”××¨×ª ×˜×™×¤×•×¡×™× ×œ-int
    df['mivne'] = df['mivne'].astype(int)
    df['area'] = df['area'].astype(int)

    with engine.begin() as conn:
        # ××—×™×§×ª ×˜×‘×œ×” ×–×× ×™×ª ×‘××™×“×” ×•×§×™×™××ª ×•×™×¦×™×¨×ª×” ××—×“×©
        conn.execute(text("""
            IF OBJECT_ID('tempdb..#temp_farms_structures') IS NOT NULL DROP TABLE #temp_farms_structures;

            CREATE TABLE #temp_farms_structures (
                farm_name NVARCHAR(50) COLLATE Hebrew_CI_AS NOT NULL,
                mivne INT NOT NULL,
                area INT NOT NULL
            );
        """))

        # ×”×•×¡×¤×ª ×©×•×¨×•×ª ×œ×˜×‘×œ×” ×”×–×× ×™×ª ××—×ª-××—×ª
        insert_sql = text("""
            INSERT INTO #temp_farms_structures (farm_name, mivne, area)
            VALUES (:farm_name, :mivne, :area)
        """)
        for _, row in df.iterrows():
            conn.execute(insert_sql, {
                "farm_name": row['farm_name'],
                "mivne": row['mivne'],
                "area": row['area']
            })

        # ×”×¨×¦×ª MERGE ×œ×”×•×¡×¤×ª ×¨×©×•××•×ª ×—×“×©×•×ª ×œ×˜×‘×œ×” ×”×¨××©×™×ª ×‘×œ×‘×“
        merge_sql = """
            MERGE dbo.farms_structures AS target
            USING #temp_farms_structures AS source
            ON 
                target.farm_name COLLATE Hebrew_CI_AS = source.farm_name COLLATE Hebrew_CI_AS
                AND target.mivne = source.mivne
                AND target.area = source.area
            WHEN NOT MATCHED BY TARGET THEN
                INSERT (farm_name, mivne, area)
                VALUES (source.farm_name, source.mivne, source.area);
        """
        result = conn.execute(text(merge_sql))
        print("âœ”ï¸ Merge completed without duplicates.")
        print(f"{result.rowcount} rows inserted.")


if __name__ == "__main__":
    # Execute the main function when the script is run independently.
    run_file()
    #run_load_area()
